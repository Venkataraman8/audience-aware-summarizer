{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XiRdTnt1B6f",
        "outputId": "c021d2b4-e1ef-4ae1-afae-8a6087c4b4a7"
      },
      "id": "3XiRdTnt1B6f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi7GwSPb15OK",
        "outputId": "9d9d7a8b-f171-456f-9b97-121ac99e8aa9"
      },
      "id": "gi7GwSPb15OK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sacremoses sacrebleu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q42Dmxi0gHfs",
        "outputId": "93600499-e601-498f-addb-e230b8c18aa6"
      },
      "id": "Q42Dmxi0gHfs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.12/dist-packages (0.1.1)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.12/dist-packages (2.5.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacremoses) (2024.11.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from sacremoses) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from sacremoses) (1.5.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sacremoses) (4.67.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (3.2.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2.0.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (5.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2dd9077-59b6-4964-82d0-4e71d3462f65",
      "metadata": {
        "id": "d2dd9077-59b6-4964-82d0-4e71d3462f65"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import html\n",
        "from typing import Dict, List\n",
        "from dataclasses import dataclass\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from datasets import load_dataset, DatasetDict\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "392b067a-2977-4ac0-a060-ec4c981474e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "392b067a-2977-4ac0-a060-ec4c981474e5",
        "outputId": "0319e0f8-1b97-477f-8933-c0f2fd31f563"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK 'punkt' data is already available.\n",
            "NLTK 'punkt_tab' data is already available.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "    print(\"NLTK 'punkt' data is already available.\")\n",
        "except LookupError:\n",
        "    print(\"Downloading NLTK sentence tokenizer data ('punkt')...\")\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    print(\"NLTK 'punkt' data downloaded.\")\n",
        "\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt_tab') # Check for punkt_tab\n",
        "    print(\"NLTK 'punkt_tab' data is already available.\")\n",
        "except LookupError:\n",
        "    print(\"NLTK 'punkt_tab' data not found. Downloading...\")\n",
        "    nltk.download('punkt_tab', quiet=True) # Download punkt_tab\n",
        "    print(\"NLTK 'punkt_tab' data downloaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36d250c0-8f3c-42be-a71a-a3db8bf8733f",
      "metadata": {
        "id": "36d250c0-8f3c-42be-a71a-a3db8bf8733f"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8870cff-fbf0-4762-afb9-92689b4d0b19",
      "metadata": {
        "id": "f8870cff-fbf0-4762-afb9-92689b4d0b19"
      },
      "source": [
        "## Model and Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f03f9197-b6e9-41c2-b98b-850aac362059",
      "metadata": {
        "id": "f03f9197-b6e9-41c2-b98b-850aac362059"
      },
      "outputs": [],
      "source": [
        "model_name = \"t5-small\"\n",
        "dataset_id = \"bogdancazan/wikilarge-text-simplification\"\n",
        "dataset_subset = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f860eea9-8ede-4952-94bf-afb7ff21903b",
      "metadata": {
        "id": "f860eea9-8ede-4952-94bf-afb7ff21903b"
      },
      "outputs": [],
      "source": [
        "source_text_column = \"Normal\"\n",
        "target_text_column = \"Simple\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b656d037-8f01-48e3-9ff3-a308a4803cb7",
      "metadata": {
        "id": "b656d037-8f01-48e3-9ff3-a308a4803cb7"
      },
      "outputs": [],
      "source": [
        "use_subset = True\n",
        "train_subset_size = 20000\n",
        "val_subset_size = 2000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "548d431b-0384-4f96-be0c-936fff66e7d5",
      "metadata": {
        "id": "548d431b-0384-4f96-be0c-936fff66e7d5"
      },
      "outputs": [],
      "source": [
        "max_source_length = 256\n",
        "max_target_length = 128\n",
        "min_source_length_chars = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4134fafa-7675-45b9-8190-7c4bf4666ec0",
      "metadata": {
        "id": "4134fafa-7675-45b9-8190-7c4bf4666ec0"
      },
      "outputs": [],
      "source": [
        "per_device_batch_size = 4\n",
        "grad_accum_steps = 4\n",
        "num_train_epochs = 3\n",
        "learning_rate = 1e-5\n",
        "weight_decay = 0.01\n",
        "warmup_ratio = 0.03\n",
        "lr_scheduler = \"cosine\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b6fd857-9188-4754-aa2d-1b6c23d56ad3",
      "metadata": {
        "id": "0b6fd857-9188-4754-aa2d-1b6c23d56ad3"
      },
      "outputs": [],
      "source": [
        "mixed_precision = \"fp16\"\n",
        "NUM_PROC = None\n",
        "gen_num_beams = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a3fe018-4136-4284-bfc2-f575e8b84281",
      "metadata": {
        "id": "7a3fe018-4136-4284-bfc2-f575e8b84281"
      },
      "source": [
        "## Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71351771-1237-4695-81cf-9cae259a55ea",
      "metadata": {
        "id": "71351771-1237-4695-81cf-9cae259a55ea"
      },
      "outputs": [],
      "source": [
        "URL_RE = re.compile(r\"https?://\\S+\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caf87f10-f8a5-4bb6-a692-6b2bd060ba0a",
      "metadata": {
        "id": "caf87f10-f8a5-4bb6-a692-6b2bd060ba0a"
      },
      "outputs": [],
      "source": [
        "def source_len_filter(example):\n",
        "    return len(example[source_text_column]) >= min_source_length_chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92e260e1-02f4-4ec2-8751-34817f910084",
      "metadata": {
        "id": "92e260e1-02f4-4ec2-8751-34817f910084"
      },
      "outputs": [],
      "source": [
        "def clean_text(t: str) -> str:\n",
        "    if t is None: # Add check for None values\n",
        "        return \"\"\n",
        "    t = str(t) # Ensure text is string\n",
        "    t = html.unescape(t)\n",
        "    t = URL_RE.sub(\"\", t)\n",
        "    t = t.replace(\"\\u00A0\", \" \")\n",
        "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "    return t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f8d9bf8-208e-4700-8c09-fcbde4db246e",
      "metadata": {
        "id": "0f8d9bf8-208e-4700-8c09-fcbde4db246e"
      },
      "outputs": [],
      "source": [
        "def cleaner_batch(batch):\n",
        "    # Apply cleaning only to the relevant columns\n",
        "    inputs = [clean_text(a) for a in batch[source_text_column]]\n",
        "    targets = [clean_text(h) for h in batch[target_text_column]]\n",
        "    return {source_text_column: inputs, target_text_column: targets}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9be87e2d-1542-4402-bdd8-cf542fd572ab",
      "metadata": {
        "id": "9be87e2d-1542-4402-bdd8-cf542fd572ab"
      },
      "source": [
        "## Load dataset + cleanup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8151d3b0-1edd-4ad7-836e-59377eb88501",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8151d3b0-1edd-4ad7-836e-59377eb88501",
        "outputId": "a35822cd-f61b-4ec9-a032-59b39773c784"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset: bogdancazan/wikilarge-text-simplification...\n"
          ]
        }
      ],
      "source": [
        "print(f\"Loading dataset: {dataset_id}...\")\n",
        "try:\n",
        "    if dataset_subset:\n",
        "        raw = load_dataset(dataset_id, dataset_subset)\n",
        "    else:\n",
        "        raw = load_dataset(dataset_id)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset: {e}\")\n",
        "    print(\"Please check the dataset ID and ensure required libraries (like gem_metrics) are installed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4343173-af93-48f9-b12c-e5c8c236054a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4343173-af93-48f9-b12c-e5c8c236054a",
        "outputId": "e3142875-c14d-4d3c-ff4c-35639ce1ca17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insufficient validation split, creating one from train split (10%)...\n",
            "Insufficient test split, creating one from train split (1%)...\n"
          ]
        }
      ],
      "source": [
        "if \"validation\" not in raw or len(raw['validation']) < 0.1 * len(raw['train']):\n",
        "    print(\"Insufficient validation split, creating one from train split (10%)...\")\n",
        "    # Take 10% of train for validation\n",
        "    train_test_split = raw[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
        "    raw = DatasetDict({\n",
        "        'train': train_test_split['train'],\n",
        "        'validation': train_test_split['test'],\n",
        "        # Keep test split if it exists, otherwise ignore\n",
        "        'test': raw.get('test')\n",
        "    })\n",
        "\n",
        "if \"test\" not in raw or len(raw['test']) < 0.01 * len(raw['train']):\n",
        "    print(\"Insufficient test split, creating one from train split (1%)...\")\n",
        "    # Take 10% of train for validation\n",
        "    train_test_split = raw[\"train\"].train_test_split(test_size=0.01, seed=42)\n",
        "    raw = DatasetDict({\n",
        "        'train': train_test_split['train'],\n",
        "        'validation': raw.get('validation'),\n",
        "        # Keep test split if it exists, otherwise ignore\n",
        "        'test': train_test_split['test']\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6ba400a-ef76-4055-85ed-8be5185232bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6ba400a-ef76-4055-85ed-8be5185232bd",
        "outputId": "c85043f0-08bd-4934-fdc2-0f6f97db00df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['Normal', 'Simple'],\n",
              "        num_rows: 132618\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['Normal', 'Simple'],\n",
              "        num_rows: 14885\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['Normal', 'Simple'],\n",
              "        num_rows: 1340\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ],
      "source": [
        "raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d3e1983-81f3-4bcc-a7b4-5d4e1f8ddf47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d3e1983-81f3-4bcc-a7b4-5d4e1f8ddf47",
        "outputId": "87d5df84-f1f8-4bff-f80f-5e238c615b02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning text...\n"
          ]
        }
      ],
      "source": [
        "print(\"Cleaning text...\")\n",
        "raw = raw.map(cleaner_batch, batched=True, num_proc=NUM_PROC, desc=\"Cleaning text\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b015033d-4402-4378-9aa8-61031a74bfca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b015033d-4402-4378-9aa8-61031a74bfca",
        "outputId": "b3f1fb24-0a9a-4645-9282-1978072db468"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering empty examples...\n"
          ]
        }
      ],
      "source": [
        "# --- Filter out empty examples after cleaning ---\n",
        "def non_empty(ex):\n",
        "    return (ex[source_text_column] and len(ex[source_text_column]) > 0) and \\\n",
        "           (ex[target_text_column] and len(ex[target_text_column]) > 0)\n",
        "\n",
        "print(\"Filtering empty examples...\")\n",
        "raw = raw.filter(non_empty, num_proc=NUM_PROC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a13eda48-1d4b-46ca-b1f9-e64794777923",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a13eda48-1d4b-46ca-b1f9-e64794777923",
        "outputId": "996085ab-b446-4e51-bf85-6ad1efa8b364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final dataset sizes:\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['Normal', 'Simple'],\n",
            "        num_rows: 132618\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['Normal', 'Simple'],\n",
            "        num_rows: 14885\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['Normal', 'Simple'],\n",
            "        num_rows: 1340\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(\"Final dataset sizes:\")\n",
        "print(raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "725703a4-a0f5-470c-9777-44b3e9cbe90d",
      "metadata": {
        "id": "725703a4-a0f5-470c-9777-44b3e9cbe90d"
      },
      "outputs": [],
      "source": [
        "def sentence_count_filter(example):\n",
        "    \"\"\"Keeps examples where source and target have the same number of sentences.\"\"\"\n",
        "    try:\n",
        "        source_sentences = nltk.sent_tokenize(example[source_text_column])\n",
        "        target_sentences = nltk.sent_tokenize(example[target_text_column])\n",
        "        return len(source_sentences) == len(target_sentences)\n",
        "    except Exception as e:\n",
        "        # Handle potential errors during tokenization (e.g., on empty strings after cleaning)\n",
        "        print(f\"Warning: Error tokenizing sentences, discarding example. Error: {e}\")\n",
        "        print(f\"Source: {example.get(source_text_column, 'N/A')}\")\n",
        "        print(f\"Target: {example.get(target_text_column, 'N/A')}\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04aba0ec-a346-4cce-b7ad-08e1aa5f64e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04aba0ec-a346-4cce-b7ad-08e1aa5f64e3",
        "outputId": "4f25abda-ec9f-4dd1-a6fa-3c987a019edf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering examples shorter than 50 characters...\n",
            "Final dataset sizes after length filtering:\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['Normal', 'Simple'],\n",
            "        num_rows: 130240\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['Normal', 'Simple'],\n",
            "        num_rows: 14626\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['Normal', 'Simple'],\n",
            "        num_rows: 1320\n",
            "    })\n",
            "})\n",
            "Applying sentence count filter...\n",
            "Final dataset sizes after sentence count filtering:\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['Normal', 'Simple'],\n",
            "        num_rows: 102965\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['Normal', 'Simple'],\n",
            "        num_rows: 11617\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['Normal', 'Simple'],\n",
            "        num_rows: 1028\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# --- Apply source length and sentence count filter ---\n",
        "print(f\"Filtering examples shorter than {min_source_length_chars} characters...\")\n",
        "raw = raw.filter(source_len_filter, num_proc=NUM_PROC, desc=f\"Filtering short sources\")\n",
        "\n",
        "print(\"Final dataset sizes after length filtering:\")\n",
        "print(raw)\n",
        "\n",
        "print(\"Applying sentence count filter...\")\n",
        "raw = raw.filter(sentence_count_filter, num_proc=NUM_PROC, desc=\"Filtering by sentence count\")\n",
        "\n",
        "print(\"Final dataset sizes after sentence count filtering:\")\n",
        "print(raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ad9fe6a-9d92-4563-9980-0dd40e4ac212",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ad9fe6a-9d92-4563-9980-0dd40e4ac212",
        "outputId": "72422102-1c06-4a46-b41f-12072239c9b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting subset: 2500 train, 200 validation...\n"
          ]
        }
      ],
      "source": [
        "if use_subset:\n",
        "    print(f\"Selecting subset: {train_subset_size} train, {val_subset_size} validation...\")\n",
        "    raw[\"train\"] = raw[\"train\"].select(range(min(train_subset_size, len(raw[\"train\"]))))\n",
        "    raw[\"validation\"] = raw[\"validation\"].select(range(min(val_subset_size, len(raw[\"validation\"]))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "343e11ac-1402-4ab2-9237-04a6f4f18a78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "343e11ac-1402-4ab2-9237-04a6f4f18a78",
        "outputId": "3f87500e-0f16-4e39-c9f0-f2eb5b446e01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final dataset sizes\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['Normal', 'Simple'],\n",
            "        num_rows: 2500\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['Normal', 'Simple'],\n",
            "        num_rows: 200\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['Normal', 'Simple'],\n",
            "        num_rows: 1028\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(\"Final dataset sizes\")\n",
        "print(raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d42e9cf7-6b1f-46f8-9be1-5288ad1ee51b",
      "metadata": {
        "id": "d42e9cf7-6b1f-46f8-9be1-5288ad1ee51b"
      },
      "source": [
        "## Tokenizer & Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "772d335d-ca6e-436b-8bb9-bacd7a01f085",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "772d335d-ca6e-436b-8bb9-bacd7a01f085",
        "outputId": "7dc136bb-2d1e-454f-d195-d81c57e4c7dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model/tokenizer: t5-small\n"
          ]
        }
      ],
      "source": [
        "print(f\"Loading model/tokenizer: {model_name}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "prefix = \"simplify: \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36b94a48-d3ea-4bad-b423-cf0655d4ba98",
      "metadata": {
        "id": "36b94a48-d3ea-4bad-b423-cf0655d4ba98"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + doc for doc in examples[source_text_column]]\n",
        "    model_inputs = tokenizer(\n",
        "        inputs,\n",
        "        max_length=max_source_length,\n",
        "        truncation=True,\n",
        "        # padding=\"max_length\",\n",
        "    )\n",
        "    # Target tokenization\n",
        "    labels = tokenizer(\n",
        "        text_target=examples[target_text_column],\n",
        "        max_length=max_target_length,\n",
        "        truncation=True,\n",
        "        # padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Mask pad tokens in labels\n",
        "    label_ids = []\n",
        "    for label_input_ids in labels[\"input_ids\"]:\n",
        "        label_ids.append([lid if lid != tokenizer.pad_token_id else -100 for lid in label_input_ids])\n",
        "\n",
        "    model_inputs[\"labels\"] = label_ids\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30768ba4-7a91-4dcd-ac34-57b3d80ab711",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "8cded50f45014a6f8489dcaa940108ed",
            "12e6f016d3f747e38488898e1e72a69d",
            "83a65e797f8f49bdb55a06be593af168",
            "b78f468392e84c89bf282ddba55952df",
            "3c9ce168909f48e9abf3df32b989f9f5",
            "95b6c51cbf46440fbbd9d8748508d40d",
            "58ed5e151b26489b82e39d2762adacf9",
            "6334b8ad52cd4c4dbbbf2c4a73b3c53d",
            "1fb53991a26043f6a8a3ed8e08f5c1f2",
            "43527de5f3ef4a86b1f3f7dd42827ef1",
            "232847c0f422462fbb3ab5c8c3836b05"
          ]
        },
        "id": "30768ba4-7a91-4dcd-ac34-57b3d80ab711",
        "outputId": "5ad90dd2-d333-4d3e-b4c9-dad6b25615f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing dataset:   0%|          | 0/200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8cded50f45014a6f8489dcaa940108ed"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(\"Tokenizing dataset...\")\n",
        "tokenized = raw.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=raw[\"train\"].column_names, # Remove original text columns\n",
        "    num_proc=NUM_PROC,\n",
        "    desc=\"Tokenizing dataset\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7c39e2b-396b-4b1c-80a5-f7ad21def378",
      "metadata": {
        "id": "a7c39e2b-396b-4b1c-80a5-f7ad21def378"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=tokenizer,\n",
        "    model=model,\n",
        "    pad_to_multiple_of=8 if mixed_precision != \"no\" else None, # Pad for efficiency with AMP\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a56cf47c-0327-4498-96f1-8e9b45749ec2",
      "metadata": {
        "id": "a56cf47c-0327-4498-96f1-8e9b45749ec2"
      },
      "outputs": [],
      "source": [
        "rouge = evaluate.load(\"rouge\")\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "sari = evaluate.load(\"sari\")\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    # Replace -100 with pad_token_id\n",
        "    preds = np.where(preds != -100, preds, tokenizer.pad_token_id)\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # --- Clean text ---\n",
        "    decoded_preds = [p.strip() for p in decoded_preds]\n",
        "    decoded_labels = [l.strip() for l in decoded_labels]\n",
        "\n",
        "    # --- ROUGE ---\n",
        "    result = rouge.compute(predictions=decoded_preds,\n",
        "                           references=decoded_labels,\n",
        "                           use_stemmer=True)\n",
        "    result = {k: round(v * 100, 2) for k, v in result.items()}\n",
        "\n",
        "    # --- BLEU ---\n",
        "    bleu_result = bleu.compute(predictions=decoded_preds,references=[[l] for l in decoded_labels])\n",
        "    result[\"bleu\"] = round(bleu_result[\"bleu\"] * 100, 2)\n",
        "\n",
        "    # --- SARI ---\n",
        "    sources = raw[\"validation\"][source_text_column][:len(decoded_preds)]\n",
        "\n",
        "    sari_result = sari.compute(\n",
        "        sources=sources,\n",
        "        predictions=decoded_preds,\n",
        "        references=[[l] for l in decoded_labels]  # list of list refs\n",
        "    )\n",
        "    result[\"sari\"] = round(sari_result[\"sari\"], 2)\n",
        "\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0618a38-9fc5-4c0b-9ba9-ef46f01c10ae",
      "metadata": {
        "id": "c0618a38-9fc5-4c0b-9ba9-ef46f01c10ae"
      },
      "source": [
        "## Training args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8a464e0-88d0-4431-a8f2-bc608e5eb80b",
      "metadata": {
        "id": "a8a464e0-88d0-4431-a8f2-bc608e5eb80b"
      },
      "outputs": [],
      "source": [
        "output_dir = f\"t5-small-wikilarge-simplifier\" # Changed output dir name\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    eval_steps=1000,             # Evaluate every 1000 steps (adjust as needed)\n",
        "    logging_steps=200,\n",
        "    save_steps=2000,\n",
        "    save_total_limit=2,\n",
        "\n",
        "    learning_rate=learning_rate,\n",
        "    per_device_train_batch_size=per_device_batch_size,\n",
        "    per_device_eval_batch_size=per_device_batch_size, # Use same batch size for eval\n",
        "    gradient_accumulation_steps=grad_accum_steps,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    weight_decay=weight_decay,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "    lr_scheduler_type=lr_scheduler, # Renamed arg\n",
        "    gradient_checkpointing=True,\n",
        "\n",
        "    predict_with_generate=True, # Needed for Seq2Seq models to generate text during eval\n",
        "    generation_max_length=max_target_length, # Use target length for generation\n",
        "    generation_num_beams=gen_num_beams,      # Use beam search during eval\n",
        "\n",
        "    fp16=(mixed_precision == \"fp16\"),\n",
        "    bf16=(mixed_precision == \"bf16\"),\n",
        "\n",
        "    report_to=[\"none\"], # Disable default reporting like wandb/tensorboard if not used\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "039135fc-1aeb-4dfa-828d-967f0f5b9691",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "039135fc-1aeb-4dfa-828d-967f0f5b9691",
        "outputId": "4901c700-8d74-4338-8ea4-6341682689be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3673763792.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        }
      ],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized[\"train\"],\n",
        "    eval_dataset=tokenized[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86e9f2c0-ae53-4f8d-8356-9f823957ad56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "86e9f2c0-ae53-4f8d-8356-9f823957ad56",
        "outputId": "c6a42f9e-b966-49bd-c4b4-4d9cbb6f3aff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='471' max='471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [471/471 07:43, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.013600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.840900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=471, training_loss=1.9151148704966163, metrics={'train_runtime': 467.3142, 'train_samples_per_second': 16.049, 'train_steps_per_second': 1.008, 'total_flos': 120352696958976.0, 'train_loss': 1.9151148704966163, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ],
      "source": [
        "print(\"Starting training...\")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4abbbc1-2bfb-4b31-935a-abcfe7c20c37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "b4abbbc1-2bfb-4b31-935a-abcfe7c20c37",
        "outputId": "80346c0d-77f8-494e-b060-f1de7c20d09d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating final model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 01:16]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(\"Evaluating final model...\")\n",
        "metrics = trainer.evaluate(max_length=max_target_length, num_beams=gen_num_beams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99bf5ae1-18b4-483c-8bec-9df2d24b416b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99bf5ae1-18b4-483c-8bec-9df2d24b416b",
        "outputId": "bf49005e-a303-4c78-c137-225e690f61f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving final model...\n",
            "Final eval metrics: {'eval_loss': 1.6726874113082886, 'eval_rouge1': 62.16, 'eval_rouge2': 45.16, 'eval_rougeL': 57.95, 'eval_rougeLsum': 58.02, 'eval_bleu': 37.85, 'eval_runtime': 77.919, 'eval_samples_per_second': 2.567, 'eval_steps_per_second': 0.642, 'epoch': 3.0}\n"
          ]
        }
      ],
      "source": [
        "print(\"Saving final model...\")\n",
        "trainer.save_model()\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "print(\"Final eval metrics:\", metrics)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rouge = evaluate.load(\"rouge\")\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "sari = evaluate.load(\"sari\")\n",
        "\n",
        "def evaluate_on_split(split_name=\"test\"):\n",
        "\n",
        "    dataset = tokenized[split_name]\n",
        "    raw_split = raw[split_name]\n",
        "\n",
        "    print(f\"Generating predictions on {split_name.upper()} split...\")\n",
        "    output = trainer.predict(\n",
        "        dataset,\n",
        "        max_length=max_target_length,\n",
        "        num_beams=gen_num_beams\n",
        "    )\n",
        "\n",
        "    pred_ids = output.predictions\n",
        "    label_ids = output.label_ids\n",
        "\n",
        "    if isinstance(pred_ids, tuple):\n",
        "        pred_ids = pred_ids[0]\n",
        "\n",
        "    pred_ids = np.where(pred_ids != -100, pred_ids, tokenizer.pad_token_id)\n",
        "    label_ids = np.where(label_ids != -100, label_ids, tokenizer.pad_token_id)\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "    decoded_preds = [p.strip() for p in decoded_preds]\n",
        "    decoded_labels = [l.strip() for l in decoded_labels]\n",
        "\n",
        "    #ROUGE\n",
        "    rouge_result = rouge.compute(\n",
        "        predictions=decoded_preds,\n",
        "        references=decoded_labels,\n",
        "        use_stemmer=True\n",
        "    )\n",
        "    rouge_result = {k: round(v * 100, 2) for k, v in rouge_result.items()}\n",
        "\n",
        "    #BLEU\n",
        "    bleu_result = bleu.compute(\n",
        "        predictions=decoded_preds,\n",
        "        references=[[l] for l in decoded_labels]\n",
        "    )\n",
        "    bleu_score = round(bleu_result[\"bleu\"] * 100, 2)\n",
        "\n",
        "    #SARI\n",
        "    sources = raw_split[split_name][source_text_column][:len(decoded_preds)]\n",
        "    sari_result = sari.compute(\n",
        "        sources=sources,\n",
        "        predictions=decoded_preds,\n",
        "        references=[[l] for l in decoded_labels]\n",
        "    )\n",
        "    sari_score = round(sari_result[\"sari\"], 2)\n",
        "\n",
        "    print(f\"\\n===== {split_name.upper()} METRICS =====\")\n",
        "    print(f\"ROUGE-1:     {rouge_result['rouge1']}\")\n",
        "    print(f\"ROUGE-2:     {rouge_result['rouge2']}\")\n",
        "    print(f\"ROUGE-L:     {rouge_result['rougeL']}\")\n",
        "    print(f\"ROUGE-Lsum:  {rouge_result['rougeLsum']}\")\n",
        "    print(f\"BLEU:        {bleu_score}\")\n",
        "    print(f\"SARI:        {sari_score}\")\n",
        "    print(\"============================\\n\")"
      ],
      "metadata": {
        "id": "8JGVz8HojkMH"
      },
      "id": "8JGVz8HojkMH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics = evaluate_on_split(split_name=\"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "WAxofsw45JgE",
        "outputId": "5411e83f-5b41-4695-c85d-27abc97c3584"
      },
      "id": "WAxofsw45JgE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1028\n",
            "1028\n",
            "Generating predictions on TEST split...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== TEST METRICS =====\n",
            "ROUGE-1: 61.12\n",
            "ROUGE-2: 43.49\n",
            "ROUGE-L: 56.76\n",
            "BLEU:    34.64\n",
            "SARI:    48.64\n",
            "============================\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (NLP Env 3.11)",
      "language": "python",
      "name": "my_nlp_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8cded50f45014a6f8489dcaa940108ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12e6f016d3f747e38488898e1e72a69d",
              "IPY_MODEL_83a65e797f8f49bdb55a06be593af168",
              "IPY_MODEL_b78f468392e84c89bf282ddba55952df"
            ],
            "layout": "IPY_MODEL_3c9ce168909f48e9abf3df32b989f9f5"
          }
        },
        "12e6f016d3f747e38488898e1e72a69d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95b6c51cbf46440fbbd9d8748508d40d",
            "placeholder": "",
            "style": "IPY_MODEL_58ed5e151b26489b82e39d2762adacf9",
            "value": "Tokenizingdataset:100%"
          }
        },
        "83a65e797f8f49bdb55a06be593af168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6334b8ad52cd4c4dbbbf2c4a73b3c53d",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1fb53991a26043f6a8a3ed8e08f5c1f2",
            "value": 200
          }
        },
        "b78f468392e84c89bf282ddba55952df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43527de5f3ef4a86b1f3f7dd42827ef1",
            "placeholder": "",
            "style": "IPY_MODEL_232847c0f422462fbb3ab5c8c3836b05",
            "value": "200/200[00:00&lt;00:00,476.04examples/s]"
          }
        },
        "3c9ce168909f48e9abf3df32b989f9f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95b6c51cbf46440fbbd9d8748508d40d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58ed5e151b26489b82e39d2762adacf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6334b8ad52cd4c4dbbbf2c4a73b3c53d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fb53991a26043f6a8a3ed8e08f5c1f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43527de5f3ef4a86b1f3f7dd42827ef1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "232847c0f422462fbb3ab5c8c3836b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}